---
title: "CAB220 Portfolio 2"
author: "KA LONG LEE (N9845097)"
date: "28/09/2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## CAB220 Portfolio2

Overview
This portfolio accounts for 20% of your overall grade of CAB220. Full mark of this portfolio is 20. The tasks in this portfolio are designed to assess your knowledge and skills in

• Descriptive statistical data analysis and visualisation 
• Statistical hypothesis testing
• Linear regression
• Logistic regression

Data:

  The fictitious data set for this portfolio includes the records of 2,550 first-year students of an Australian university in terms of case ID, Attrition, Degree Type, Achieved Credit Points, Attendance Type, Age, Failed Credit Points, International student, First in family in university, Gender, GPA, OP Score, Socio Economic Status, Teaching Period Admitted,and Faculty.

Working Environment Configuration:

```{r eval=TRUE,message=FALSE}

# Import Library
library(ggplot2)
library(dplyr)

# Setting up the working directory
# So that It can import external file
# Warning!!! -- Disable the next line, if you need to export the pdf report
#               Otherwise, you will need the next line to generates diagram later on
# setwd(dirname(rstudioapi::getActiveDocumentContext()$path))

# Import external files
# Most of the visualization function is stored in this file
# Please check it if you are interested in the code
source("data_visualization.R")

# Import Data 
uniData <- read.csv("datasets/Portfolio_2_data.csv", header = TRUE) %>%
  select(2:15)

```

## Task 1 Summarise the information in each variable (except case ID) using a table or an appropriate statistical graph

#### Summary each variables using a table

```{r eval=TRUE}
summary(uniData)
```
#### Summary each categorical data in uni dataframe using appropriate graphs

```{r eval=TRUE}
visualize_categorical_data(uniData)
```
  
  The function operated above generates 9 bar charts illustrating the distribution of each categorical variables in the data frame. The summaries of each chart are listed below.
  
### 1. The distribution of the attrition of the students
  It is evident that students in retained attrition are approximately four times more than students in not retained attrition. 
      
### 2. The distribution of degree type among students
  Almost 93% of students are doing a single degree, while the rest are doing a double degree.

### 3. The attendance type distribution among students
  Not surprisingly, most of the students are studying full-time at university. On the other hand, around ten per cent of students is a part-time student.
      
### 4. The distribution of first in family in all the students
  There are approximately 95% of students are local students in the university, while the remainder is international students.
  
### 5. The distribution of gender among students
  It is interesting that gender in the university is evenly distributed. It doesn't have a huge statistical outliner.

### 6. The economic status of each students. 
  Half proportion of the students are in medium-income families. Approximately 30 per cent of students are in high-income families, while around 18% of students were heavily concerning their economic status.

### 7. The distribution of the period students admitted to university
  The chart shows that approximately 80 per cent of the students joined the university in semester 1, while only 20 per cent of students admitted by the university in semester 2.
  
### 8. The distribution of students in each faculty
  Both Faculty of Health, Science and Engineering contain the most amount of student, while CI Faculty and Business School contain the second most amount of student. Faculty of Education, however, has the least amount of student enrolled in the recorded period.


#### Summary each numerical data using appropriate graphs

```{r eval=TRUE}
# A function print out each appropriate graphs
visualize_numerical_data(uniData)
```

The function operated above generates one density graphs and four histogram illustrating the distribution of each numerical variables in the data frame. The summaries of each chart are listed below.
  
### 1. The distribution of the age of the students

   Not surprisingly, most of the students are around 17 and 19 years old. They normally enrolled in the university after graduated from high school. However, also some students are over 20 years old. It could be some students enrolled in the university after finishing a lower education, such as a diploma or certificate IV.
  
### 2. The distribution of achieved credit points among students
  The histogram does not show any interesting fact to be noted. Most of the students in the record are in second year of their study.

### 3. The GPA distribution among students
  Most of the student average around a GPA of 4 to 6. It can be summarised that there are approximately 80% of student with a GPA higher than 3.5, while the remainders are with a lower GPA less than 3.5.
      
### 4. The OP Score distribution among students
  Clearly, most of the students get OP score around 5 to 10. The diagram occurs right-skewed.
  
### 5.The distribution of failed credit points among students
  Not surprisingly, most of the students are highly possible that never fail any unit (0 point) or one single unit (12 point). It makes the diagrams tend to be frequent on the left-hand side.

## Task 2 Compare average GPA between male and female students using a graph, conduct a statistical test, and interpret its results

### Summary GPA for male
```{r eval=TRUE}
male_data <- uniData %>%
  filter(Gender == "M") 

summary(male_data$GPA)
```

### Summary GPA for Female
```{r eval=TRUE}
female_data <- uniData %>%
  filter(Gender == "F") 

summary(female_data$GPA)
```

```{r eval=TRUE}
# Compare average GPA between Male and Female 
# Conduct a statistical Test
# Interpret its results
visualize_boxplot_gpa_vs_gender(uniData)
```

### T-Test & Variance
```{r eval=TRUE}
# T Test
t.test(uniData$GPA ~ uniData$Gender)
# Variance
var.test(uniData$GPA ~ uniData$Gender)
```


## Task3 Explore the relationship between OP Score and GPA using a graph, describe the relationship
```{r eval=TRUE}
visualize_relationship_op_and_gpa(uniData)
```

### Bar chart (OP Score VS GPA)
  The first bar chart displayed the relationship between OP score and GPA. Each bar indicates every student achieves in the OP exam, while each bar is filled with 8 different colours which indicate how these students perform in the university. The GPA score is rounded to the nearest integer, for instance, 3.67 will be rounded to 4 and 6.18 will be rounded to 6.
  
  Most of the students, who get the lowerest OP exam, tend to perform better in the university. Approximately 50% of students, who get 1 OP score, archived above GPA 6 when they are studying in university. In contrast, about 40% of students, who get 25 OP score, archived below GPA 4 which means failed the study in university.
  
  In conclusion, if students get the lower OP scores tends to performs better in the university.

## Task 4 Linear Regression

Develop a linear regression model of GPA using the given data. You need to describe your choice of predictors, examine your model’s assumptions, assess model fit, and interpret the final model’s regression coefficients.

Analyse Each numerical data its relation related to GPA

## Correlation between each numerical data and GPA
  1. Age : `r cor(uniData$Age, uniData$GPA)`
  2. OP_Score : `r cor(uniData$OP_Score, uniData$GPA)`
  3. Achieved_Credit_Points : `r cor(uniData$Achieved_Credit_Points, uniData$GPA)`
  4. Failed_Credit_Points : `r cor(uniData$Failed_Credit_Points, uniData$GPA)`

```{r eval=TRUE,message=FALSE, warning=FALSE}
visualize_scatterplots_Vs_GPA(uniData)
```

### The chosen predictors
  It is evident that GPA will always be selected to be Y-axis which is classified as quantitative value. The predictor will need to be a strong data value that could have a significant impact on the analysis. From the correlation score and scatterplot we get above, Achieved Credit Point seems to be a biased and homoscedastic graph. It provides a good fit for the linear regression model as it has a positive linear relationship and a positive correlation value. It also achieves the highest correlation score which indicates that it has the strongest relationship with GPA comparing to the other three. Therefore, Achieved Credit Point is selected to train and test the simple linear regression model.

### Spiting dataframe into training set and test set
```{r eval=TRUE}
# Data Preprocessing Library
library(caTools)
# Set Random seed
set.seed(2)
# Splitting Training and test dataset
split <- sample.split(uniData, SplitRatio = 0.7)
train <- subset(uniData, split==TRUE)
test <- subset(uniData, split==FALSE)

```

### Training Linear Regression Model & Review diagnostic measures.
```{r eval=TRUE}
linear_model <- lm(GPA ~ Achieved_Credit_Points, data=train)
summary(linear_model)
```
### Plot the Linear Regression Prediction Line
```{r eval=TRUE}
plot(linear_model)
```

## Task 5 Logistic Regression

```{r eval=TRUE, message=FALSE}
# Logistic Regression Library
library(DAAG)
source("regression_helper.R")
```

### Bivariate exploration
```{r eval=TRUE}
xtabs(~ uniData$Attrition + uniData$Socio_Economic_Status)
```

### A simple model with only one predictor
```{r eval=TRUE}
simple_log_model <- glm(Attrition ~ Socio_Economic_Status, data=uniData, family = "binomial")
summary(simple_log_model)
```

### simple model P-value & Pseudo R^2 
```{r eval=TRUE}
print_R2_and_pvalue(simple_log_model$null.deviance, simple_log_model$deviance)
```

### Summarise the predicted probailities
```{r eval=TRUE}
simple.predicted.data <- data.frame(
  probability.of.Attrition = simple_log_model$fitted.values,
  Socio_Economic_Status = uniData$Socio_Economic_Status
)

xtabs(~ probability.of.Attrition + Socio_Economic_Status ,data=simple.predicted.data)
```

### Logistic Regression model with all predictors
```{r}
# Logistic Regression with all predictors
log_model <- glm(Attrition ~ ., data=uniData, family = "binomial")
summary(log_model)
```

### Logistic Regression model with all predictors P-value & Pseudo R^2 
```{r eval=TRUE}
print_R2_and_pvalue(log_model$null.deviance, log_model$deviance)
```

### Multicollinearity using VIF
```{r eval=TRUE}
vif(log_model)
```

### Plot Predicted Probabilities 
```{r eval=TRUE, message=FALSE}
predicted.data <- data.frame(
  probability.of.Attrition = log_model$fitted.values,
  Attrition = uniData$Attrition
)

# Sort predicted data by Probabilities
predicted.data <- predicted.data[order(predicted.data$probability.of.Attrition, decreasing = FALSE),]
predicted.data$rank <- 1:nrow(predicted.data)

library(ggplot2)
library(cowplot)

ggplot(data=predicted.data, aes(x=rank, y=probability.of.Attrition) ) +
  geom_point(aes(color=Attrition), alpha = 1, shape = 4, stroke = 2) +
  xlab("Index") +
  ylab("Predicted probability of Attrition")
```

## ROC Curve
```{r eval=TRUE}
# 
predicted.data$actuals <- factor(predicted.data$Attrition, labels = c(0,1))
# Shows ROC Curve
visualize_ROC_Curve(predicted.data$actuals, predicted.data$probability.of.Attrition)
```

### MisClassification Error, Sensitivity, Specificity
```{r eval=TRUE}
print_MCE_Sens_Spec( predicted.data$actuals, predicted.data$probability.of.Attrition)
```

```{r eval=TRUE}
print_ConfusionMatrix( predicted.data$actuals, predicted.data$probability.of.Attrition)
```
